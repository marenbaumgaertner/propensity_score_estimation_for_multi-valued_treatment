---
title: "Replication of Archarky (2023)"
author: "Maren Baumg√§rtner"
output: html_notebook
---
This notebook replicates the results of Table 2 and Table 6 of the paper "Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects" from Acharky (2023) using their code and adding a plot to visualize the results.
```{r}
# Import libraries and dataset
library(dplyr)
library(reshape2)
library(randomForest)
library(ggplot2)
library(grf)
library(tidyverse)
source("MetaLearners_tools.R")
#source("Meta_Learners.Rmd")
set.seed(1234)
```
## Define functions for prediction evaluation
The `outcome()` function is  a linear prediction depending on the treatment status `t` and the confounders `X`.
```{r}
outcome <- function(t, X){
  return( (1+t)*X )
}
```

The  `PEHE()` function computes the Precision in Estimation of Heterogeneous Effect (PEHE). The input arguments are the estimated CATE of a Meta Learner `hat_tau`, the confounders matrix `X` and the considered treatment status `t`. The function computes the true treatment effect `tau` as the difference in outcome `Y` when receiving treatment `t` and the out come when receiving the baseline treatment (no treatment) using the `outcome()` function. The PEHE is defined as the mean of the squared difference in the true `tau`  and the Meta learner `hat_tau`. It is a vector of length K-1.
```{r}
PEHE <- function(hat_tau, X, t){
  tau = outcome(t, X) -  outcome(0, X) # ground truth
  return( mean((hat_tau - tau)^2) )
}
```

The functions `mPEHE()`and `sPEHE()` return the mean PEHE and the standard deviation of the PEHE. The input argument PEHE is
```{r}
mPEHE <- function(PEHE){
  return(sqrt(mean(PEHE)))
}

sdPEHE <- function(PEHE){
  return(sqrt(sd(PEHE)))
}
```
## Create a sample dataset
```{r}
n = 2000
K = 10
X = runif(0, 1, n = n)
W = sample(seq(0, 1, by = 1/(K-1)), replace = TRUE, n) # sample(0:(K-1), replace = TRUE, n)
W.levels <- sort(unique(W))
Y = outcome(W, X) +  rnorm(n, sd = 0.05)
dataset = data.frame(Frac_length_ft = X, W = W, Y = Y)

```

### GPS estimation
Note: different methods for GSP estimation coming soon
```{r}
W_int = W*(K-1)
w_fit = xgboost(data = as.matrix(sapply(X, as.numeric)), label = W_int, verbose = F,
                nrounds = 100, num_class = K, objective = "multi:softprob", eval_metric = "mlogloss") 
r_hat = as.data.frame(predict(w_fit, as.matrix(X), reshape = T))

```


## Meta-Learners (xgboost)
For each Meta-Learner I compute the `.Fit` and the `_hat` element before evaluating the predictions using the PEHE. The `.Fit` element is a (large) list of K/K-1 "sublists". Each sublist 
The `_hat` is a list of K vectors containing the predictions of the considered Meta-Learner for each treatment status `t`. There are estimates (a seperate model?) for each treatment status `t`.

### T_learner 
The `.Fit` element is a (large) list of K "sublists". Each sublist 
```{r}
T.Fit = T_Learner(as.data.frame(X), Y, W, model = "xgboost")

T_hat = list()
for(k in 1:K){
  T_hat[[k]] = predict(T.Fit[[k]], as.matrix(X))
}

PEHE_T = c()
for(k in 2:K){
  PEHE_T= c(PEHE_T, PEHE(T_hat[[k]] - T_hat[[1]], X, W.levels[k]))
}
mPEHE_T = mPEHE(PEHE_T)
mPEHE_T

sdPEHE_T = sdPEHE(PEHE_T)
sdPEHE_T

```

### S_learner 
The `S.Fit` element is a list of K-1 element. Each element 
```{r}
S.Fit = S_Learner(as.data.frame(X), Y, W, model = "xgboost")

S_hat = list()
for(k in 1:K){
  w = W.levels[k]
  S_hat[[k]] = predict(S.Fit, as.matrix(data.frame(X, W = rep(w, nrow(dataset)) )))
}

PEHE_S = c()
for(k in 2:K){
  PEHE_S= c(PEHE_S, PEHE(S_hat[[k]] - S_hat[[1]], X, W.levels[k]))
}
mPEHE_S = mPEHE(PEHE_S)
mPEHE_S

sdPEHE_S = sdPEHE(PEHE_S)
sdPEHE_S
```

### Naive X_learner 
```{r}
nvX_hat = nvX_Learner(as.data.frame(X), Y, W, r_hat, T.Fit, model = "xgboost")

PEHE_nvX = c()
for(k in 2:K){
  PEHE_nvX= c(PEHE_nvX, PEHE(nvX_hat[[k-1]], X, W.levels[k]))
}
mPEHE_nvX = mPEHE(PEHE_nvX)
mPEHE_nvX

sdPEHE_nvX = sdPEHE(PEHE_nvX)
sdPEHE_nvX
```

### M_learner

```{r}
M.Fit = M_Learner(as.matrix(X), Y, W, r_hat, model = "xgboost")

M_hat = list()
for(k in 1:K){
  M_hat[[k]] = predict(M.Fit[[k]], as.matrix(X))
}

PEHE_M = c()
for(k in 2:K){
  PEHE_M= c(PEHE_M, PEHE(M_hat[[k]] - M_hat[[1]], X, W.levels[k]))
}

mPEHE_M = mPEHE(PEHE_M)
mPEHE_M

sdPEHE_M = sdPEHE(PEHE_M)
sdPEHE_M
```

### DR_learner with T-learning nuisance

```{r}
mu_T = rep(0, n)
mu_hat = data.frame(mu_T = mu_T)
for(k in 1:K){
  w = W.levels[k]
  mu_hat$mu_T[which(W==w)] = T_hat[[k]][which(W==w)];
  mu_hat = cbind(mu = T_hat[[K-k+1]], mu_hat)
}


DR.Fit = DR_Learner(as.matrix(X), Y, W, r_hat, mu_hat, model = "xgboost")

DR_hat = list()
for(k in 1:K){
  DR_hat[[k]] = predict(DR.Fit[[k]], as.matrix(X))
}

PEHE_DR = c()
for(k in 2:K){
  PEHE_DR = c(PEHE_DR, PEHE(DR_hat[[k]] - DR_hat[[1]], X, W.levels[k]))
}

mPEHE_DRT = mPEHE(PEHE_DR)
mPEHE_DRT

sdPEHE_DRT = sdPEHE(PEHE_DR)
sdPEHE_DRT
```

### X_learner with T-learning
```{r}
X.Fit = X_Learner(as.matrix(X), Y, W, mu_hat, model = "xgboost")

X_hat = list()
for(k in 1:(K-1)){
  X_hat[[k]] = predict(X.Fit[[k]], as.matrix(X))
}

PEHE_X = c()
for(k in 2:K){
  PEHE_X = c(PEHE_X, PEHE(X_hat[[k-1]], X, W.levels[k]))
}

mPEHE_XT = mPEHE(PEHE_X)
mPEHE_XT

sdPEHE_XT = sdPEHE(PEHE_X)
sdPEHE_XT
```

### DR_learner with S-learning nuisance

```{r}
mu_T = rep(0, n)
mu_hat = data.frame(mu_T = mu_T)
for(k in 1:K){
  w = W.levels[k]
  mu_hat$mu_T[which(W==w)] = S_hat[[k]][which(W==w)];
  mu_hat = cbind(mu = S_hat[[K-k+1]], mu_hat)
}

DR.Fit = DR_Learner(as.matrix(X), Y, W, r_hat, mu_hat, model = "xgboost")

DR_hat = list()
for(k in 1:K){
  DR_hat[[k]] = predict(DR.Fit[[k]], as.matrix(X))
}

PEHE_DR = c()
for(k in 2:K){
  PEHE_DR = c(PEHE_DR, PEHE(DR_hat[[k]] - DR_hat[[1]], X, W.levels[k]))
}

mPEHE_DR = mPEHE(PEHE_DR)
mPEHE_DR

sdPEHE_DR = sdPEHE(PEHE_DR)
sdPEHE_DR
```

### X_learner with S-learning

```{r}
X.Fit = X_Learner(as.matrix(X), Y, W, mu_hat, model = "xgboost")

X_hat = list()
for(k in 1:(K-1)){
  X_hat[[k]] = predict(X.Fit[[k]], as.matrix(X))
}

PEHE_X = c()
for(k in 2:K){
  PEHE_X = c(PEHE_X, PEHE(X_hat[[k-1]], X, W.levels[k]))
}

mPEHE_X = mPEHE(PEHE_X)
mPEHE_X

sdPEHE_X = sdPEHE(PEHE_X)
sdPEHE_X
```

### R_learner linear family

```{r}
y_fit = xgboost(data = as.matrix(sapply(X, as.numeric)), label = Y, nrounds = 100,  verbose = F)
m_hat = predict(y_fit, as.matrix(X), reshape = T)

Freg = as.matrix(cbind(intercept = rep(1,nrow(dataset)), X, X^2))
p = ncol(Freg)
beta_R = R_Learner_reg(as.matrix(X), Y, W, r_hat, m_hat, Freg = Freg) 

R_hat = list()
for(k in 1:(K-1)){
  R_hat[[k]] = Freg %*% beta_R[((k-1)*p+1):(k*p)]
}

PEHE_R = c()
for(k in 2:K){
  PEHE_R = c(PEHE_R, PEHE(R_hat[[k-1]], X, W.levels[k]))
}

mPEHE_R = mPEHE(PEHE_R)
mPEHE_R


sdPEHE_R = sdPEHE(PEHE_R)
sdPEHE_R
```


```{r}
Xgb_results = data.frame(mPEHE_T = mPEHE_T, mPEHE_S = mPEHE_S, mPEHE_nvX = mPEHE_nvX, mPEHE_M = mPEHE_M,
           mPEHE_DR = mPEHE_DR, mPEHE_X = mPEHE_X, mPEHE_Rlin = mPEHE_R)
Xgb_results
```


### Causal forest
```{r}
CF.Fit <- multi_arm_causal_forest(as.data.frame(X), Y, as.factor(W))

CF_hat <- as.matrix(predict(CF.Fit)$predictions[, , 1])

PEHE_CF = c()
for(k in 2:K){
  PEHE_CF= c(PEHE_CF, PEHE(CF_hat[,k-1], X, W.levels[k]))
}

mPEHE_CF = mPEHE(PEHE_CF)
mPEHE_CF

sdPEHE_CF = sdPEHE(PEHE_CF)
sdPEHE_CF
```

## Visualization of PEHE

```{r}
#PEHEs$mean <- cbind(mPEHE_T, mPEHE_S)#, mPEHE_nvX, mPEHE_M, mPEHE_DR, mPEHE_X, mPEHE_R)

PEHEs <- as.tibble(c(mPEHE_T, mPEHE_S, mPEHE_nvX, mPEHE_M, mPEHE_DRT, mPEHE_XT, mPEHE_DR, mPEHE_X, mPEHE_R, mPEHE_CF)) %>% rename(mean=value)
PEHEs$sd <- c(sdPEHE_T, sdPEHE_S, sdPEHE_nvX, sdPEHE_M, sdPEHE_DRT, sdPEHE_XT, sdPEHE_DR, sdPEHE_X, sdPEHE_R, sdPEHE_CF)
PEHEs$rowname <- c("T-Learner", "S-Learner", "naive X-Learner", "M-Learner", 
                   "DR-Learner w/ T-learning ", "X-Learner w/ T-learning ",
                   "DR-Learner w/ S-learning ", "X-Learner w/ S-learning ",
                   "R-Learner", "Causal Forest")
ggplot(PEHEs, aes(x = rowname, y = mean, ymin = mean - 1.96*sd, ymax = mean + 1.96*sd)) +
  geom_errorbar(width = 0.2) +
  geom_point(size = 1.5) +
    xlab("Meta-Learner") +
    ylab("mPEHE") +
    ggtitle('') +
  theme_bw() + theme (axis.text.x = element_text (angle = 90))
```


```{r}
# Exclude R-Learner and M-Learner
PEHEs_xgb <- as.tibble(c(mPEHE_T, mPEHE_S, mPEHE_nvX, mPEHE_DRT, mPEHE_XT, mPEHE_DR, mPEHE_X, mPEHE_CF)) %>% rename(mean=value)
PEHEs_xgb$sd <- c(sdPEHE_T, sdPEHE_S, sdPEHE_nvX, sdPEHE_DRT, sdPEHE_XT, sdPEHE_DR, sdPEHE_X, sdPEHE_CF)
PEHEs_xgb$rowname <- c("T-Learner", "S-Learner", "naive X-Learner", 
                   "DR-Learner w/ T-learning ", "X-Learner w/ T-learning ",
                   "DR-Learner w/ S-learning ", "X-Learner w/ S-learning ",
                   "Causal Forest")

ggplot(PEHEs_xgb, aes(x = rowname, y = mean, ymin = mean - 1.96*sd, ymax = mean + 1.96*sd)) +
  geom_errorbar(width = 0.2) +
  geom_point(size = 1.5) +
  xlab("Meta-Learner") +
  ylab("mPEHE") +
  ggtitle('XGBoost') +
  theme_bw() + theme (axis.text.x = element_text (angle = 90)) 
  
```
## Meta-Learners (random Forest)

### T-learner :
```{r}


T.Fit = T_Learner(as.data.frame(X), Y, W, model = "randomForest")

T_hat = list()
for(k in 1:K){
  T_hat[[k]] = predict(T.Fit[[k]], as.matrix(X))
}

PEHE_T = c()
for(k in 2:K){
  PEHE_T= c(PEHE_T, PEHE(T_hat[[k]] - T_hat[[1]], X, W.levels[k]))
}
mPEHE_T = mPEHE(PEHE_T)
mPEHE_T

sdPEHE_T = sdPEHE(PEHE_T)
sdPEHE_T
```


### S-Learner
```{r}
S.Fit = S_Learner(as.data.frame(X), Y, W, model = "randomForest")

S_hat = list()
for(k in 1:K){
  w = W.levels[k]
  S_hat[[k]] = predict(S.Fit, as.matrix(data.frame(X, W = rep(w, nrow(dataset)) )))
}

PEHE_S = c()
for(k in 2:K){
  PEHE_S= c(PEHE_S, PEHE(S_hat[[k]] - S_hat[[1]], X, W.levels[k]))
}
mPEHE_S = mPEHE(PEHE_S)
mPEHE_S

sdPEHE_S = sdPEHE(PEHE_S)
sdPEHE_S
```

### naive X-Learner
```{r}
nvX_hat = nvX_Learner(as.matrix(X), Y, W, r_hat, T.Fit, model = "randomForest")

PEHE_nvX = c()
for(k in 2:K){
  PEHE_nvX= c(PEHE_nvX, PEHE(nvX_hat[[k-1]], X, W.levels[k]))
}
mPEHE_nvX = mPEHE(PEHE_nvX)
mPEHE_nvX

sdPEHE_nvX = sdPEHE(PEHE_nvX)
sdPEHE_nvX
```

### M-Learner
```{r}
M.Fit = M_Learner(as.matrix(X), Y, W, r_hat, model = "randomForest")

M_hat = list()
for(k in 1:K){
  M_hat[[k]] = predict(M.Fit[[k]], as.matrix(X))
}

PEHE_M = c()
for(k in 2:K){
  PEHE_M= c(PEHE_M, PEHE(M_hat[[k]] - M_hat[[1]], X, W.levels[k]))
}

mPEHE_M = mPEHE(PEHE_M)
mPEHE_M

sdPEHE_M = sdPEHE(PEHE_M)
sdPEHE_M
```

### DR-Learner w/ T-learning
```{r}
mu_T = rep(0, n)
mu_hat = data.frame(mu_T = mu_T)
for(k in 1:K){
  w = W.levels[k]
  mu_hat$mu_T[which(W==w)] = T_hat[[k]][which(W==w)];
  mu_hat = cbind(mu = T_hat[[K-k+1]], mu_hat)
}

DR.Fit = DR_Learner(as.matrix(X), Y, W, r_hat, mu_hat, model = "randomForest")

DR_hat = list()
for(k in 1:K){
  DR_hat[[k]] = predict(DR.Fit[[k]], as.matrix(X))
}

PEHE_DR = c()
for(k in 2:K){
  PEHE_DR = c(PEHE_DR, PEHE(DR_hat[[k]] - DR_hat[[1]], X, W.levels[k]))
}

mPEHE_DRT = mPEHE(PEHE_DR)
mPEHE_DRT

sdPEHE_DRT = sdPEHE(PEHE_DR)
sdPEHE_DRT
```

### X-Learner w/ T-learning
```{r}
X.Fit = X_Learner(as.matrix(X), Y, W, mu_hat, model = "randomForest")

X_hat = list()
for(k in 1:(K-1)){
  X_hat[[k]] = predict(X.Fit[[k]], as.matrix(X))
}

PEHE_X = c()
for(k in 2:K){
  PEHE_X = c(PEHE_X, PEHE(X_hat[[k-1]], X, W.levels[k]))
}

mPEHE_XT = mPEHE(PEHE_X)
mPEHE_XT

sdPEHE_XT = sdPEHE(PEHE_X)
sdPEHE_XT
```

### DR-Learner w/ S-learning
```{r}
mu_T = rep(0, n)
mu_hat = data.frame(mu_T = mu_T)
for(k in 1:K){
  w = W.levels[k]
  mu_hat$mu_T[which(W==w)] = S_hat[[k]][which(W==w)];
  mu_hat = cbind(mu = S_hat[[K-k+1]], mu_hat)
}

DR_hat = list()
for(k in 1:K){
  DR_hat[[k]] = predict(DR.Fit[[k]], as.matrix(X))
}

PEHE_DR = c()
for(k in 2:K){
  PEHE_DR = c(PEHE_DR, PEHE(DR_hat[[k]] - DR_hat[[1]], X, W.levels[k]))
}

mPEHE_DR = mPEHE(PEHE_DR)
mPEHE_DR

sdPEHE_DR = sdPEHE(PEHE_DR)
sdPEHE_DR
```

### X-Learner w/ S-learning
```{r}
X.Fit = X_Learner(as.matrix(X), Y, W, mu_hat, model = "randomForest")

X_hat = list()
for(k in 1:(K-1)){
  X_hat[[k]] = predict(X.Fit[[k]], as.matrix(X))
}

PEHE_X = c()
for(k in 2:K){
  PEHE_X = c(PEHE_X, PEHE(X_hat[[k-1]], X, W.levels[k]))
}

mPEHE_X = mPEHE(PEHE_X)
mPEHE_X

sdPEHE_X = sdPEHE(PEHE_X)
sdPEHE_X
```

### R-Learner
```{r}
y_fit = randomForest(x = as.matrix(X), y = Y)
m_hat = predict(y_fit, as.matrix(X), reshape = T)

Freg = as.matrix(cbind(intercept = rep(1,nrow(dataset)), X, X^2))
p = ncol(Freg)
beta_R = R_Learner_reg(as.matrix(X), Y, W, r_hat, m_hat, Freg = Freg) 

R_hat = list()
for(k in 1:(K-1)){
  R_hat[[k]] = Freg %*% beta_R[((k-1)*p+1):(k*p)]
}

PEHE_R = c()
for(k in 2:K){
  PEHE_R = c(PEHE_R, PEHE(R_hat[[k-1]], X, W.levels[k]))
}

mPEHE_R = mPEHE(PEHE_R)
mPEHE_R

sdPEHE_R = sdPEHE(PEHE_R)
sdPEHE_R
```



```{r}
# Exclude R-Learner and M-Learner
PEHEs_rf <- as.tibble(c(mPEHE_T, mPEHE_S, mPEHE_nvX, mPEHE_DRT, mPEHE_XT, mPEHE_DR, mPEHE_X, mPEHE_CF)) %>% rename(mean=value)
PEHEs_rf$sd <- c(sdPEHE_T, sdPEHE_S, sdPEHE_nvX, sdPEHE_DRT, sdPEHE_XT, sdPEHE_DR, sdPEHE_X, sdPEHE_CF)
PEHEs_rf$rowname <- c("T-Learner", "S-Learner", "naive X-Learner", 
                   "DR-Learner w/ T-learning ", "X-Learner w/ T-learning ",
                   "DR-Learner w/ S-learning ", "X-Learner w/ S-learning ",
                   "Causal Forest")

ggplot(PEHEs_rf, aes(x = rowname, y = mean, ymin = mean - 1.96*sd, ymax = mean + 1.96*sd)) +
  geom_errorbar(width = 0.2) +
  geom_point(size = 1.5) +
  xlab("Meta-Learner") +
  ylab("mPEHE") +
  ggtitle('Random Forest') +
  theme_bw() + theme (axis.text.x = element_text (angle = 90)) 
  
```


## Meta-Learners (linear Regression)

### T-learner 
```{r}
T.Fit = T_Learner(as.data.frame(X), Y, W, model = "lm", p = 2)

T_hat = list()
for(k in 1:K){
  T_hat[[k]] = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% T.Fit[[k]]$coefficients
}

PEHE_T = c()
for(k in 2:K){
  PEHE_T = c(PEHE_T, PEHE(T_hat[[k]] - T_hat[[1]], X, W.levels[k]))
}
mPEHE_T = mPEHE(PEHE_T)
mPEHE_T

sdPEHE_T = sdPEHE(PEHE_T)
sdPEHE_T
```

### S-learner :
```{r}
S.Fit = S_Learner(as.data.frame(X), Y, W, model = "lm", p = 2)

S_hat = list()
for(k in 1:K){
  df_k = data.frame(X = X, W = rep(W.levels[k], nrow(dataset)))
  S_hat[[k]] = as.matrix(data.frame(Intercept = rep(1, nrow(df_k)), polym( as.matrix(df_k), degree = 2, raw = T))) %*% S.Fit$coefficients
}

PEHE_S = c()
for(k in 2:K){
  PEHE_S = c(PEHE_S, PEHE(S_hat[[k]] - S_hat[[1]], X, W.levels[k]))
}
mPEHE_S = mPEHE(PEHE_S)
mPEHE_S

sdPEHE_S = sdPEHE(PEHE_S)
sdPEHE_S
```

### naive X-Learner
```{r}
nvX_hat = nvX_Learner(as.matrix(X), Y, W, r_hat, T.Fit, model = "lm", p = 2)

PEHE_nvX = c()
for(k in 2:K){
  PEHE_nvX= c(PEHE_nvX, PEHE(nvX_hat[[k-1]], X, W.levels[k]))
}
mPEHE_nvX = mPEHE(PEHE_nvX)
mPEHE_nvX

sdPEHE_nvX = sdPEHE(PEHE_nvX)
sdPEHE_nvX
```

### M-Learner
```{r}
M.Fit = M_Learner(as.matrix(X), Y, W, r_hat, model = "lm", p = 2)

M_hat = list()
for(k in 1:K){
  M_hat[[k]] = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% M.Fit[[k]]$coefficients
}

PEHE_M = c()
for(k in 2:K){
  PEHE_M = c(PEHE_M, PEHE(M_hat[[k]] - M_hat[[1]], X, W.levels[k]))
}
mPEHE_M = mPEHE(PEHE_M)
mPEHE_M

sdPEHE_M = sdPEHE(PEHE_M)
sdPEHE_M
```

### DR-Learner w/ T-learning
```{r}
mu_T = rep(0, n)
mu_hat = data.frame(mu_T = mu_T)
for(k in 1:K){
  w = W.levels[k]
  mu_hat$mu_T[which(W==w)] = T_hat[[k]][which(W==w)];
  mu_hat = cbind(mu = T_hat[[K-k+1]], mu_hat)
}

DR.Fit = DR_Learner(as.matrix(X), Y, W, r_hat, mu_hat, model = "lm", p = 2)

DR_hat = list()
for(k in 1:K){
  DR_hat[[k]] = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% DR.Fit[[k]]$coefficients
}

PEHE_DR = c()
for(k in 2:K){
  PEHE_DR = c(PEHE_DR, PEHE(DR_hat[[k]] - DR_hat[[1]], X, W.levels[k]))
}
mPEHE_DRT = mPEHE(PEHE_DR)
mPEHE_DRT

sdPEHE_DRT = sdPEHE(PEHE_DR)
sdPEHE_DR
```

### X-Learner w/ T-learning
```{r}
X.Fit = X_Learner(as.matrix(X), Y, W, mu_hat, model = "lm", p = 2)

X_hat = list()
for(k in 2:K){
  X_hat[[k-1]] = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% X.Fit[[k-1]]$coefficients
}

PEHE_X = c()
for(k in 2:K){
  PEHE_X = c(PEHE_X, PEHE(X_hat[[k-1]], X, W.levels[k]))
}
mPEHE_XT = mPEHE(PEHE_X)
mPEHE_XT

sdPEHE_XT = sdPEHE(PEHE_X)
sdPEHE_X
```

### DR-Learner w/ S-learning
```{r}
mu_T = rep(0, n)
mu_hat = data.frame(mu_T = mu_T)
for(k in 1:K){
  w = W.levels[k]
  mu_hat$mu_T[which(W==w)] = S_hat[[k]][which(W==w)];
  mu_hat = cbind(mu = S_hat[[K-k+1]], mu_hat)
}


DR.Fit = DR_Learner(as.matrix(X), Y, W, r_hat, mu_hat, model = "lm", p = 2)

DR_hat = list()
for(k in 1:K){
  DR_hat[[k]] = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% DR.Fit[[k]]$coefficients
}

PEHE_DR = c()
for(k in 2:K){
  PEHE_DR = c(PEHE_DR, PEHE(DR_hat[[k]] - DR_hat[[1]], X, W.levels[k]))
}
mPEHE_DR = mPEHE(PEHE_DR)
mPEHE_DR

sdPEHE_DR = sdPEHE(PEHE_DR)
sdPEHE_DR
```

### X-Learner w/ S-learning
```{r}
X.Fit = X_Learner(as.matrix(X), Y, W, mu_hat, model = "lm", p = 2)

X_hat = list()
for(k in 2:K){
  X_hat[[k-1]] = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% X.Fit[[k-1]]$coefficients
}

PEHE_X = c()
for(k in 2:K){
  PEHE_X = c(PEHE_X, PEHE(X_hat[[k-1]], X, W.levels[k]))
}
mPEHE_X = mPEHE(PEHE_X)
mPEHE_X

sdPEHE_X = sdPEHE(PEHE_X)
sdPEHE_X
```

### R-Learner
```{r}
y_fit = lm(Y ~ polym( as.matrix(X), degree = 2, raw=T))
m_hat = as.matrix(data.frame(Intercept = rep(1, nrow(dataset)), polym( as.matrix(X), degree = 2, raw=T))) %*% y_fit$coefficients

Freg = as.matrix(cbind(intercept = rep(1,nrow(dataset)), X, X^2))
p = ncol(Freg)
beta_R = R_Learner_reg(as.matrix(X), Y, W, r_hat, m_hat, Freg = Freg) 

R_hat = list()
for(k in 1:(K-1)){
  R_hat[[k]] = Freg %*% beta_R[((k-1)*p+1):(k*p)]
}

PEHE_R = c()
for(k in 2:K){
  PEHE_R = c(PEHE_R, PEHE(R_hat[[k-1]], X, W.levels[k]))
}

mPEHE_R = mPEHE(PEHE_R)
mPEHE_R

sdPEHE_R = sdPEHE(PEHE_R)
sdPEHE_R
```



```{r}
# Exclude R-Learner and M-Learner
PEHEs_lm <- as.tibble(c(mPEHE_T, mPEHE_S, mPEHE_nvX, mPEHE_DRT, mPEHE_XT, mPEHE_DR, mPEHE_X, mPEHE_CF)) %>% rename(mean=value)
PEHEs_lm$sd <- c(sdPEHE_T, sdPEHE_S, sdPEHE_nvX, sdPEHE_DRT, sdPEHE_XT, sdPEHE_DR, sdPEHE_X, sdPEHE_CF)
PEHEs_lm$rowname <- c("T-Learner", "S-Learner", "naive X-Learner", 
                   "DR-Learner w/ T-learning ", "X-Learner w/ T-learning ",
                   "DR-Learner w/ S-learning ", "X-Learner w/ S-learning ",
                   "Causal Forest")

ggplot(PEHEs_lm, aes(x = rowname, y = mean, ymin = mean - 1.96*sd, ymax = mean + 1.96*sd)) +
  geom_errorbar(width = 0.2) +
  geom_point(size = 1.5) +
  xlab("Meta-Learner") +
  ylab("mPEHE") +
  ggtitle('') +
  theme_bw() + theme (axis.text.x = element_text (angle = 90)) 
  
```

