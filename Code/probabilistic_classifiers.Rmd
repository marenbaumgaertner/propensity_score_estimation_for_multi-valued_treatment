---
title: "Probabilistic Classifiers"
author: "Maren BaumgÃ¤rtner"
output: 
  html_notebook:
    toc: true
    toc_float: true
    code_folding: show
---

```{r, message=FALSE, echo=FALSE,warning=FALSE}
# Import libraries and dataset
library(knitr)
library(plyr)
library(dplyr)
library(reshape2)
library(randomForest)
library(ggplot2)
library(caTools)
library(mlogit)
library(nnet)
library(caret)
library(glmnet)
library(naivebayes)
library(rpart)
library(randomForest)
library(MASS)
library(FNN)
library(e1071)
library(igraph)
library(caret)
library(sparklyr)
library(RSSL)
library(sgd)
library(MASS)
library(hdm)
library(predtools)
library(xgboost)
library(adabag)
library(rpart)
library(grf)
library(ada)
library(fastAdaboost)
library(causalDML)
library(binda)
library(kknn)
library(calibrate)
library(bartMachine)
library(ranger)
```

```{r}
source("ml_wrapper.R")
source("eval_functions.R")

set.seed(42)
options(scipen= 999)
```

# Create binary data

```{r, warning=FALSE}
# Set parameters
n = 3000
p = 10

# Draw sample
X = matrix(runif(n*p,-pi,pi),ncol=p)
e = function(x){2/13} # balanced
#e = function(x){pnorm(sin(x))}
m0 = function(x){sin(x)}
tau = function(x){1*(x>-0.5*pi)}
#m1 = function(x){m0(x) + tau(x)}
W = rbinom(n,1,e(X))
Y = m0(X[,1]) + W*tau(X[,1]) + rnorm(n,0,1/2)


W.levels <- sort(unique(W))
K <- length(W.levels)


#dataset_f <- data.frame(W = as.factor(W),X) # with W as factor
dataset <- data.frame(W=W,X)

split_indices <- sample.split(dataset$W, SplitRatio = 0.8)
training_data <- dataset[split_indices, ]
test_data <- dataset[!split_indices, ]

#training_data_f <- dataset_f[split_indices, ]
#test_data_f <- dataset_f[!split_indices, ]

W_training <- as.matrix(data.frame(W = training_data$W))
X_training <- as.matrix(data.frame(X[split_indices, ]))
W_test <-     as.matrix(data.frame(W = test_data$W))
X_test <-     as.matrix(data.frame(X[!split_indices, ]))
```

# Train binary classifiers

```{r, warning=FALSE}
# List of classifiers
classifiers <- c(
  "adaboost", "bagging", "bart", "boosting", "knn",
  "knn_radius", "lda", "logit",
  "mlpc","multinom", "nb_bernulli", "nb_gaussian",
  "probability_forest", "qda", "ranger", "svm", "xgboost"
)

# Initialize a list to store results
results_binary <- list()
classifier <- classifiers[14]

# use uniform distribution of probabilities as benchmark
predictions = matrix(1/K, nrow = nrow(test_data), ncol = 1)
bs = brier_score(probabilities= predictions, outcome=W_test, binary = FALSE)
results_binary[["uniform"]] = list(predictions = predictions, brier_score = bs)


# Loop through classifiers
for (classifier in classifiers) {
  print(classifier)
  # Create model
  model <- do.call(paste0(classifier, "_fit"), list(x=X_training, y=W_training))
  
  # Make predictions
  predictions <- do.call(paste0("predict.", classifier,  "_fit"), 
                         list(model, X_test, W_training, xnew = X_test))$prediction
  
  #print(colnames(predictions))
  predictions = as_tibble(predictions) %>% select("1")

  # Calculate Brier score
  bs <- brier_score(probabilities = predictions, outcome = W_test)
  
  # Make calibration plot
  plot_filename <- paste(classifier, ".png", sep = "")
  make_calibtation_plot(predictions, as_tibble(W_test), classifier)
  
  # Store results
  results_binary[[classifier]] <- list(predictions = predictions, brier_score = bs)
}


```

# Evaluation

## Brier Score

```{r, message=FALSE, echo=FALSE}
brier_scores <- sapply(results_binary, function(result) result$brier_score)

# Create a data frame with classifier names and Brier scores
results_df <- data.frame(Classifier = c("uniform", classifiers), Brier_Score = brier_scores) %>% arrange(Brier_Score)

# Display the table using kable
kable(results_df, caption = "Brier Scores for Classifiers")
```

## Calibration plots

```{r}
make_calibtation_plot(results_binary$adaboost$predictions, as_tibble(W_test), "adaboost")
make_calibtation_plot(results_binary$bagging$predictions, as_tibble(W_test), "bagging")
make_calibtation_plot(results_binary$bart$predictions, as_tibble(W_test), "bart")
make_calibtation_plot(results_binary$boosting$predictions, as_tibble(W_test), "boosting")
make_calibtation_plot(results_binary$knn$predictions, as_tibble(W_test), "KNN")
make_calibtation_plot(results_binary$knn_radius$predictions, as_tibble(W_test), "KNN Radius")
make_calibtation_plot(results_binary$lda$predictions, as_tibble(W_test), "LDA")
make_calibtation_plot(results_binary$logit$predictions, as_tibble(W_test), "Logistic regression")
make_calibtation_plot(results_binary$mlpc$predictions, as_tibble(W_test), "MLPC")
make_calibtation_plot(results_binary$multinom$predictions, as_tibble(W_test), "Multinomial penalized regression")
make_calibtation_plot(results_binary$nb_bernulli$predictions, as_tibble(W_test), "Naive Bayes (Bernulli)")
make_calibtation_plot(results_binary$nb_gaussian$predictions, as_tibble(W_test), "Naive Bayes (Gaussian)")
make_calibtation_plot(results_binary$probability_forest$predictions, as_tibble(W_test), "Probability Forest")
make_calibtation_plot(results_binary$ranger$predictions, as_tibble(W_test), "Ranger")
make_calibtation_plot(results_binary$qda$predictions, as_tibble(W_test), "QDA")
make_calibtation_plot(results_binary$svm$predictions, as_tibble(W_test), "SVM")
make_calibtation_plot(results_binary$xgboost$predictions, as_tibble(W_test), "XGBoost")
```

# Create multi-valued data

```{r}
n=2000
K=4
p=5

W <- sample(seq(1, K, by = 1), replace = TRUE, n)
X = matrix(runif(n*p,-pi,pi),ncol=p)


W.levels <- sort(unique(W))
K <- length(W.levels)


#dataset_f <- data.frame(W = as.factor(W),X) # with W as factor
dataset <- data.frame(W=W,X)

split_indices <- sample.split(dataset$W, SplitRatio = 0.8)
training_data <- dataset[split_indices, ]
test_data <- dataset[!split_indices, ]

#training_data_f <- dataset_f[split_indices, ]
#test_data_f <- dataset_f[!split_indices, ]

W_training <- as.matrix(data.frame(W = training_data$W))
X_training <- as.matrix(data.frame(X[split_indices, ]))
W_test <-     as.matrix(data.frame(W = test_data$W))
X_test <-     as.matrix(data.frame(X[!split_indices, ]))

```

# Train multi-valued classifier

```{r}
# List of classifiers
classifiers <- c(
  "bagging", "knn",
  "knn_radius", "lda",
  "mlpc", "nb_bernulli", "nb_gaussian", "ovo",
  "probability_forest", "qda", "ranger", "xgboost"
)

# Initialize a list to store results
results <- list()
classifier=classifiers[3]

# use uniform distribution of probabilities as benchmark
predictions = matrix(1/K, nrow = nrow(test_data), ncol = K)
bs = brier_score(predictions, W_test, binary = FALSE)
results[["uniform"]] = list(predictions = predictions, brier_score = bs)

# Loop through classifiers
for (classifier in classifiers) {
  print(classifier)
  # Create model
  model <- do.call(paste0(classifier, "_fit"), list(x=X_training, y=W_training))
  
  # Make predictions
  predictions <- do.call(paste0("predict.", classifier,  "_fit"), 
                         list(model, X_test, W_test, xnew = X_test))$prediction
  
  
  predictions = predictions %>% as_tibble()
  if (colnames(predictions)[1] != "1"){
    colnames(predictions) <- seq.int(1, ncol(predictions))
  }
  
   # Reorder the columns in the dataframe
  predictions <- predictions[, order(names(predictions))]
  
  # Calculate Brier score
  bs <- brier_score(predictions, W_test, binary = FALSE)
  
  # Store results
  results[[classifier]] <- list(predictions = predictions, brier_score = bs)
}


```

# Evaluation

## Brier Score

```{r, message=FALSE, echo=FALSE}
brier_scores <- sapply(results, function(result) result$brier_score)

# Create a data frame with classifier names and Brier scores
results_df <- data.frame(Classifier = c("uniform", classifiers), Brier_Score = brier_scores) %>% arrange(Brier_Score)

# Display the table using kable
kable(results_df, caption = "Brier Scores for Classifiers")
```

## Calibration plots

```{r}
make_calibtation_plot(results$bagging$predictions, as_tibble(W_test), "bagging")
make_calibtation_plot(results$boosting$predictions, as_tibble(W_test), "boosting")
make_calibtation_plot(results$knn$predictions, as_tibble(W_test), "KNN")
make_calibtation_plot(results$knn_radius$predictions, as_tibble(W_test), "KNN Radius")
make_calibtation_plot(results$lda$predictions, as_tibble(W_test), "LDA")
make_calibtation_plot(results$logit$predictions, as_tibble(W_test), "Logistic regression")
make_calibtation_plot(results$mlpc$predictions, as_tibble(W_test), "MLPC")
make_calibtation_plot(results$nb_bernulli$predictions, as_tibble(W_test), "Naive Bayes (Bernulli)")
make_calibtation_plot(results$nb_gaussian$predictions, as_tibble(W_test), "Naive Bayes (Gaussian)")
make_calibtation_plot(results$probability_forest$predictions, as_tibble(W_test), "Probability Forest")
make_calibtation_plot(results$qda$predictions, as_tibble(W_test), "QDA")
make_calibtation_plot(results$svm$predictions, as_tibble(W_test), "SVM")
make_calibtation_plot(results$xgboost$predictions, as_tibble(W_test), "XGBoost")
```

# Train multi-valued classifier using OvO

```{r}

# List of classifiers
classifiers <- c(
  "adaboost", "bagging", "bart", "boosting", "knn",
  "knn_radius", "lda", "logit",
  "mlpc","multinom", "nb_bernulli", "nb_gaussian",
  "probability_forest", "qda", "ranger", "svm", "xgboost"
)

# Initialize a list to store results
results_ovo <- list()
classifier=classifiers[3]

# use uniform distribution of probabilities as benchmark

# Loop through classifiers
for (classifier in classifiers) {
  print(classifier)
  # Create model
  model <- do.call(ovo_fit, list(x=X_training, y=W_training, classifier=classifier))
  
  # Make predictions
  predictions <- do.call(predict.ovo_fit, 
                         list(model, X_test, W_training, xnew = X_test, classifier=classifier))$prediction
  
   # Reorder the columns in the dataframe
  predictions <- predictions[, order(names(predictions))]
  
  # Calculate Brier score
  bs <- brier_score(predictions, W_test, binary = FALSE)
  
  # Make calibration plot
  #plot_filename <- paste(classifier, ".png", sep = "")
  #make_calibtation_plot(predictions, as_tibble(W_test), classifier)
  
  # Store results
  results_ovo[[classifier]] <- list(predictions = predictions, brier_score = bs)
}


```

## Brier Score

```{r, message=FALSE, echo=FALSE}
brier_scores <- sapply(results_ovo, function(result) result$brier_score)

# Create a data frame with classifier names and Brier scores
results_df <- data.frame(Classifier = classifiers, Brier_Score = brier_scores) %>% arrange(Brier_Score)

# Display the table using kable
kable(results_df, caption = "Brier Scores for Classifiers")
```

## Calibration plots

```{r}
make_calibtation_plot(results_ovo$adaboost$predictions, as_tibble(W_test), "adaboost")
make_calibtation_plot(results_ovo$bagging$predictions, as_tibble(W_test), "bagging")
make_calibtation_plot(results_ovo$bart$predictions, as_tibble(W_test), "bart")
make_calibtation_plot(results_ovo$boosting$predictions, as_tibble(W_test), "boosting")
make_calibtation_plot(results_ovo$knn$predictions, as_tibble(W_test), "KNN")
make_calibtation_plot(results_ovo$knn_radius$predictions, as_tibble(W_test), "KNN Radius")
make_calibtation_plot(results_ovo$lda$predictions, as_tibble(W_test), "LDA")
make_calibtation_plot(results_ovo$logit$predictions, as_tibble(W_test), "Logistic regression")
make_calibtation_plot(results_ovo$mlpc$predictions, as_tibble(W_test), "MLPC")
make_calibtation_plot(results_ovo$multinom$predictions, as_tibble(W_test), "Multinomial penalized regression")
make_calibtation_plot(results_ovo$nb_bernulli$predictions, as_tibble(W_test), "Naive Bayes (Bernulli)")
make_calibtation_plot(results_ovo$nb_gaussian$predictions, as_tibble(W_test), "Naive Bayes (Gaussian)")
make_calibtation_plot(results_ovo$probability_forest$predictions, as_tibble(W_test), "Probability Forest")
make_calibtation_plot(results_ovo$ranger$predictions, as_tibble(W_test), "Ranger")
make_calibtation_plot(results_ovo$qda$predictions, as_tibble(W_test), "QDA")
make_calibtation_plot(results_ovo$svm$predictions, as_tibble(W_test), "SVM")
make_calibtation_plot(results_ovo$xgboost$predictions, as_tibble(W_test), "XGBoost")
```

# Train multi-valued classifier using OvR

```{r}

# List of classifiers
classifiers <- c(
  "adaboost", "bagging", "bart", "boosting", "knn",
  "knn_radius", "lda", "logit",
  "mlpc","multinom", "nb_bernulli", "nb_gaussian",
  "probability_forest", "qda", "ranger", "svm", "xgboost"
)

# Initialize a list to store results
results_ovr <- list()
#classifier=classifiers[5]

# use uniform distribution of probabilities as benchmark

# Loop through classifiers
for (classifier in classifiers) {
  print(classifier)
  # Create model
  model <- do.call(ovr_fit, list(x=X_training, y=W_training, classifier=classifier))
  
  # Make predictions
  predictions <- do.call(predict.ovr_fit, 
                         list(model, X_test, W_test, xnew = X_test, classifier=classifier))$prediction
  
  
   # Reorder the columns in the dataframe
  predictions <- predictions[, order(names(predictions))]
  
  # Calculate Brier score
  bs <- brier_score(predictions, W_test, binary = FALSE)
  
  # Make calibration plot
  #plot_filename <- paste(classifier, ".png", sep = "")
  #make_calibtation_plot(predictions, as_tibble(W_test), classifier)
  
  # Store results
  results_ovr[[classifier]] <- list(predictions = predictions, brier_score = bs)
}


```

## Brier Score

```{r, message=FALSE, echo=FALSE}
brier_scores <- sapply(results_ovr, function(result) result$brier_score)

# Create a data frame with classifier names and Brier scores
results_df <- data.frame(Classifier = classifiers, Brier_Score = brier_scores) %>% arrange(Brier_Score)

# Display the table using kable
kable(results_df, caption = "Brier Scores for Classifiers")
```

## Calibration plots

```{r}
make_calibtation_plot(results_ovr$adaboost$predictions, as_tibble(W_test), "adaboost")
make_calibtation_plot(results_ovr$bagging$predictions, as_tibble(W_test), "bagging")
make_calibtation_plot(results_ovr$bart$predictions, as_tibble(W_test), "bart")
make_calibtation_plot(results_ovr$boosting$predictions, as_tibble(W_test), "boosting")
make_calibtation_plot(results_ovr$knn$predictions, as_tibble(W_test), "KNN")
make_calibtation_plot(results_ovr$knn_radius$predictions, as_tibble(W_test), "KNN Radius")
make_calibtation_plot(results_ovr$lda$predictions, as_tibble(W_test), "LDA")
make_calibtation_plot(results_ovr$logit$predictions, as_tibble(W_test), "Logistic regression")
make_calibtation_plot(results_ovr$mlpc$predictions, as_tibble(W_test), "MLPC")
make_calibtation_plot(results_ovr$multinom$predictions, as_tibble(W_test), "Multinomial penalized regression")
make_calibtation_plot(results_ovr$nb_bernulli$predictions, as_tibble(W_test), "Naive Bayes (Bernulli)")
make_calibtation_plot(results_ovr$nb_gaussian$predictions, as_tibble(W_test), "Naive Bayes (Gaussian)")
make_calibtation_plot(results_ovr$probability_forest$predictions, as_tibble(W_test), "Probability Forest")
make_calibtation_plot(results_ovr$ranger$predictions, as_tibble(W_test), "Ranger")
make_calibtation_plot(results_ovr$qda$predictions, as_tibble(W_test), "QDA")
make_calibtation_plot(results_ovr$svm$predictions, as_tibble(W_test), "SVM")
make_calibtation_plot(results_ovr$xgboost$predictions, as_tibble(W_test), "XGBoost")
```

```{r}
# Define the negative log-likelihood function
neg_log_likelihood <- function(p, q_hat) {
  # Check for non-finite values in the vector 'p'
  if (any(!is.finite(p))) {
    return(Inf)
  }
  
  # Calculate negative log-likelihood
  sum(q_hat * log(q_hat / p))
}

# Given matrix of pairwise probabilities
q_matrix <- matrix(c(NA, 0.9, 0.4, 0.1, NA, 0.7, 0.6, 0.3, NA), nrow = 3, byrow = TRUE)

# Optimization: Find p that minimizes negative log-likelihood
result <- optim(par = c(0.33, 0.33, 0.33), fn = neg_log_likelihood(q_hat = q_matrix, p=par), method = "L-BFGS-B")

# Extract the optimized probabilities
optimized_p <- result$par

print(optimized_p)

```

```{r}
# Define the negative log-likelihood function
neg_log_likelihood <- function(p, q_hat) {
   p_mat <- matrix(p, nrow = length(p), ncol = length(p))
  ll <- -sum(q_hat * log(q_hat /p_mat))
}

# Given matrix of pairwise probabilities
q_matrix <- matrix(c(0.1, 0.9, 0.4, 0.1, 0.1, 0.7, 0.6, 0.3, 0.1), nrow = 3, byrow = TRUE)

# Optimization: Find p that minimizes negative log-likelihood
result <- optim(par = c(0.33, 0.33, 0.33), 
                fn = neg_log_likelihood, 
                q_hat = q_matrix,
                method = "L-BFGS-B")


# Extract the optimized probabilities
optimized_p <- result$par

print(optimized_p)

```

```{r}
# Define the negative log-likelihood function
neg_log_likelihood <- function(p, q_hat) {
  # Exclude NA values from the calculation
  valid_indices <- is.finite(q_hat) & is.finite(p)
  -sum(q_hat[valid_indices] * log(q_hat[valid_indices] / p[valid_indices]))
}

# Given matrix of pairwise probabilities
q_matrix <- matrix(c(NA, 0.9, 0.4, 0.1, NA, 0.7, 0.6, 0.3, NA), nrow = 3, byrow = TRUE)

# Optimization: Find p that minimizes negative log-likelihood
result <- optim(par = c(0.50, 0.25, 0.25), fn = neg_log_likelihood, NULL, q_hat = q_matrix, method = "CG")

# Extract the optimized probabilities
optimized_p <- result$par

print(optimized_p)

neg_log_likelihood(0.5, 0.9)

```

```{r}
# Define the negative log-likelihood function
neg_log_likelihood <- function(q_hat, p) {
  # Reshape p to a matrix for element-wise operations
  p_matrix <- matrix(p, nrow = nrow(q_hat), ncol = ncol(q_hat), byrow = TRUE)
  
  # Avoid log(0) issues by replacing 0 with a small value
  p_matrix[p_matrix == 0] <- 1e-10
  
  # Calculate the negative log-likelihood
  ll <- -sum(q_hat * log(q_hat / p_matrix))
  if(is.na(ll)) ll <- 0
  
  return(ll)
}

# Given matrix of pairwise probabilities
q_matrix <- matrix(c(NA, 0.9, 0.4, 0.1, NA, 0.7, 0.6, 0.3, NA), nrow = 3, byrow = TRUE)

# Optimization: Find p that minimizes negative log-likelihood
result <- optim(par = c(0.33, 0.33, 0.33), 
                fn = neg_log_likelihood, 
                q_hat = q_matrix, 
                method = "L-BFGS-B")

# Extract the optimized probabilities
optimized_p <- result$par

# Print the optimized probabilities
print(optimized_p)

```

```{r}
# Define the negative log-likelihood function
neg_log_likelihood <- function(p, q_hat) {
  p_matrix <- matrix(p, nrow = dim(q_hat)[1], ncol = dim(q_hat)[2], byrow = TRUE)
  
  # Exclude NA values from the calculations
  valid_entries <- !is.na(q_hat)
  
  # Calculate the negative log-likelihood only for valid entries
  ll <- -sum(q_hat[valid_entries] * log(q_hat[valid_entries] / p_matrix[valid_entries]))
 
  
  return(ll)
}

# Given matrix of pairwise probabilities
q_matrix <- matrix(c(NA, 0.9, 0.4, 0.1, NA, 0.7, 0.6, 0.3, NA), nrow = 3, byrow = TRUE)


# Optimization: Find p that minimizes negative log-likelihood
result <- optim(par = c(0.33, 0.33, 0.33), 
                fn = neg_log_likelihood, 
                q_hat = q_matrix, 
                method = "BFGS",
                lower = rep(1e-6, length(par)), 
                upper = rep(1e-6, length(par)))

# Extract the optimized probabilities
optimized_p <- result$par

# Print the optimized probabilities
print(optimized_p)

neg_log_likelihood(p=p_matrix, q_hat = q_matrix)

```
